{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05.Transfer_Learning.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8912_r3u8rn"
      },
      "source": [
        "# [실습05] 합성공 신경망(2)_Transfer Learning\n",
        "## 휴먼지능정보공학과 201910841 최다경\n",
        "\n",
        "## https://github.com/DaGyeongChoi\n",
        "\n",
        "## 1.Settings\n",
        "### 1) Important required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cd5hmJa5UDY"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "#!cd /content/gdrive/MyDrive/\n",
        "#%cd /content/gdrive/MyDrive/ex_05/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3lycbRrAimX"
      },
      "source": [
        "!unzip '/content/horse-or-human.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyi9DPVeWTzK"
      },
      "source": [
        "!unzip '/content/animal+utils.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOReoJmuu1X9"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMzXJ9KDvGGa"
      },
      "source": [
        "### 2) Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyYXqRgBu8HZ"
      },
      "source": [
        "batch_size= 16 #64  #1\n",
        "learning_rate = 0.0001\n",
        "epoch = 20\n",
        "\n",
        "n_node = 1024  # customized last layer 의 노드 수. 64, 128, 256, 512, 1024\n",
        "dropratio = 0.5   # 얼마나 드랍시킬지 inverse keepratio \n",
        "\n",
        "imgsize = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj1IEx5MvJiu"
      },
      "source": [
        "## 2.Data Loader\n",
        "### 트레이닝 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylOBXPFLvHsY"
      },
      "source": [
        "#img_dir='../../../images/painting_dataset/real_artwork_divided_shffl_4K/Train'\n",
        "#img_dir=\"animal/train\"\n",
        "img_dir=\"train\"\n",
        "train_data=dset.ImageFolder(img_dir, transforms.Compose([\n",
        "            transforms.CenterCrop(imgsize*2), #CenterCop(512)\n",
        "            transforms.RandomCrop(imgsize), #RandomCrop\n",
        "            transforms.RandomHorizontalFlip(), #RandomHorizontalFlip\n",
        "            transforms.Resize(imgsize),\n",
        "            transforms.ToTensor()    \n",
        "            ]))\n",
        "print(train_data.__len__())\n",
        "train_batch=data.DataLoader(train_data, batch_size=batch_size,\n",
        "                           shuffle=True,num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYOzOSvIyeLK"
      },
      "source": [
        "### 고정된 데이터 셋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKcZTv_rvLI6"
      },
      "source": [
        "#2. Dev data\n",
        "#img_dir='../../../images/painting_dataset/real_artwork_divided_shffl_4K/Valid'\n",
        "# img_dir=\"animal/val\"\n",
        "img_dir=\"val\"\n",
        "dev_data=dset.ImageFolder(img_dir, transforms.Compose([\n",
        "            transforms.CenterCrop(size=imgsize),\n",
        "            transforms.Resize(imgsize),\n",
        "            transforms.ToTensor()    \n",
        "            ]))\n",
        "\n",
        "dev_batch=data.DataLoader(dev_data, batch_size=batch_size,\n",
        "                           shuffle=False,num_workers=2)\n",
        "\n",
        "#3. Test data\n",
        "# img_dir=\"animal/test\"\n",
        "img_dir=\"test\"\n",
        "test_data=dset.ImageFolder(img_dir, transforms.Compose([\n",
        "            transforms.CenterCrop(size=imgsize),\n",
        "            transforms.Resize(imgsize),\n",
        "            transforms.ToTensor()    \n",
        "            ]))\n",
        "\n",
        "test_batch=data.DataLoader(test_data, batch_size=batch_size,\n",
        "                           shuffle=False,num_workers=2)\n",
        "\n",
        "\n",
        "nclass=len(train_data.classes)\n",
        "print(\"# of classes: %d\" %nclass)\n",
        "print(train_data.classes)\n",
        "print(train_data.class_to_idx)\n",
        "print(train_data.__len__())\n",
        "\n",
        "print(\"Training: %d, Dev: %d, Test: %d\"\n",
        "     %(train_data.__len__(), dev_data.__len__(), test_data.__len__()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTNBugPEyfre"
      },
      "source": [
        "print(train_data.classes)\n",
        "print(dev_data.classes)\n",
        "print(test_data.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADe_IVz5yjvY"
      },
      "source": [
        "## 3.Model\n",
        "### 1) Pretrained VGG Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTV4eOywyhbu"
      },
      "source": [
        "vgg=models.vgg19(pretrained =True)\n",
        "\n",
        "for name,module in vgg.named_children():\n",
        "    print(name)\n",
        "    \n",
        "print(list(vgg.children())[0])\n",
        "print(list(vgg.children())[-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uolM5t-NB36R"
      },
      "source": [
        "print(list(vgg.children())[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pD0Wsxpym-p"
      },
      "source": [
        "### 2)Customized Fully Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSWBlEMVylKB"
      },
      "source": [
        "base_dim=64\n",
        "fsize=int(imgsize/32)\n",
        "\n",
        "class MyVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyVGG,self).__init__()\n",
        "        #[0]: features(conv), [1]: classifier(fc)\n",
        "        self.layer0=nn.Sequential(*list(vgg.children())[0])\n",
        "        \n",
        "        self.layer1=nn.Sequential(\n",
        "            nn.Linear(8*base_dim*fsize*fsize,n_node),\n",
        "            nn.BatchNorm1d(n_node),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(dropratio),\n",
        "        \n",
        "            nn.Linear(n_node,n_node),\n",
        "            nn.BatchNorm1d(n_node),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(dropratio),\n",
        "        \n",
        "            nn.Linear(n_node,n_node),\n",
        "            nn.BatchNorm1d(n_node),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(dropratio),\n",
        "            \n",
        "            nn.Linear(n_node, nclass),        \n",
        "            )\n",
        "        \n",
        "        for m in self.layer1.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.kaiming_normal(m.weight.data)\n",
        "                m.bias.data.fill_(0)\n",
        "            if isinstance(m, nn.Linear):\n",
        "                init.kaiming_normal(m.weight.data)\n",
        "                m.bias.data.fill_(0)\n",
        "                    \n",
        "    def forward(self,x):\n",
        "        out=self.layer0(x)\n",
        "        out=out.view(out.size(0),-1)\n",
        "        out=self.layer1(out)\n",
        "        return out   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOlsq6_JyqnX"
      },
      "source": [
        "### 3) Model on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWg_eDXbyoo4"
      },
      "source": [
        "model=MyVGG().cuda()\n",
        "\n",
        "for params in model.layer0.parameters():\n",
        "    params.required_grad =False\n",
        "    \n",
        "for params in model.layer1.parameters():\n",
        "    params.required_grad =True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXj5ayBIyx7I"
      },
      "source": [
        "for name in model.children():\n",
        "    print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL8fKkUK2Y0W"
      },
      "source": [
        "## 4. Optimizer & Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybW4PMkV2CtS"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.layer1.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz7vH0EI2b-5"
      },
      "source": [
        "## 5. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXuVvFVb2aJR"
      },
      "source": [
        "import utils \n",
        "total_time=0\n",
        "disp_step=10\n",
        "\n",
        "to_train = True\n",
        "if (to_train == False):\n",
        "    # netname='./nets/catdog_vgg19_10.pkl'\n",
        "    netname='./nets/horsehuman.pkl'\n",
        "    model=torch.load(netname)\n",
        "else:\n",
        "    print(\"3 layer, n_node: %d, dropratio: %.2f\" %(n_node,dropratio))\n",
        "    model.eval()\n",
        "    train_corr=utils.ComputeCorr(train_batch, model)\n",
        "    dev_corr=utils.ComputeCorr(dev_batch, model)\n",
        "    test_corr=utils.ComputeCorr(test_batch, model)\n",
        "    print(\"Correct of train: %.2f, dev: %.2f, test: %.2f\"\n",
        "         %(train_corr, dev_corr, test_corr))\n",
        "    model.train()\n",
        "    netname='./nets/horsehuman1'\n",
        "    \n",
        "    x_epoch=[]\n",
        "    y_train_err=[]\n",
        "    y_dev_err=[]\n",
        "    y_test_err=[]\n",
        "    \n",
        "    x_epoch.append(0)\n",
        "    y_train_err.append(100.0-train_corr)\n",
        "    y_dev_err.append(100.0-dev_corr)\n",
        "    y_test_err.append(100.0-test_corr)\n",
        "    \n",
        "    for i in range(epoch):\n",
        "        start_time=time.time()\n",
        "        print(\"%d..\"%i),\n",
        "        for img,label in train_batch:\n",
        "            img=Variable(img).cuda()\n",
        "            label=Variable(label).cuda()\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output=model(img)\n",
        "            loss=loss_func(output,label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        end_time=time.time()\n",
        "        duration=end_time-start_time\n",
        "        total_time += duration\n",
        "        if (i % disp_step==0) or (i==epoch-1):\n",
        "            torch.save(model, netname+'_%d.pkl'%i,)\n",
        "            print(\"\\n[%d/%d] loss: %.3f, \" %(i, epoch, (loss.cpu()).data.numpy())),\n",
        "            model.eval()\n",
        "            train_corr = utils.ComputeCorr(train_batch, model)\n",
        "            dev_corr = utils.ComputeCorr(dev_batch, model)\n",
        "            test_corr = utils.ComputeCorr(test_batch, model)\n",
        "            print(\"Correct of train: %.2f, dev: %.2f, test: %2f, \"\n",
        "                 %(train_corr, dev_corr, test_corr)),\n",
        "            model.train()\n",
        "            print(\"time: %.2f sec..\" %(total_time))\n",
        "            \n",
        "            x_epoch.append(i+1)\n",
        "            y_train_err.append(100.0-train_corr)\n",
        "            y_dev_err.append(100.0-dev_corr)\n",
        "            y_test_err.append(100.0-test_corr)\n",
        "        print(\"Total time: %.2f sec\" %total_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Bvg0p_2dY4"
      },
      "source": [
        "if (to_train):\n",
        "    plt.plot(x_epoch, y_train_err, color='black', label='train err', linestyle='--')\n",
        "    plt.plot(x_epoch, y_dev_err, color='red', label='dev err')\n",
        "    plt.plot(x_epoch, y_test_err, color='blue', label='test err')\n",
        "    \n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('err')\n",
        "    plt.title('epoch&err graph')\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McUx_OFF3HhI"
      },
      "source": [
        "## 6.Evaluation for dev & test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQqvni_f3EYS"
      },
      "source": [
        "model.eval()\n",
        "utils.EvaluateClassifier(dev_batch, model, dev_data.classes, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTI28QIm3LHc"
      },
      "source": [
        "model.eval()\n",
        "_, _,_ = utils.EvaluateClassifier(test_batch, model, test_data.classes, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90yrea8e3MJ-"
      },
      "source": [
        "utils.VisTFPred(dev_batch, model, test_data.classes, batch_size, i_n=2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}